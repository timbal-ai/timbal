---
title: "Tracing"
description: "Understanding execution traces and target resolution in evals"
---

Evals validate your agent's behavior by inspecting its execution trace. This guide explains how traces work and how to target specific values for validation.

## What is a Trace?

When your agent runs, Timbal records a trace of the execution - a hierarchical record of every operation, including:

- LLM calls
- Tool invocations
- Input and output values
- Timing information
- Token usage

Evals use this trace to validate that your agent behaved correctly.

## Trace Structure

A trace is organized as a tree of **spans**, where each span represents an operation:

```
agent (root span)
├── llm (first LLM call)
├── get_datetime (tool call)
│   ├── input: { timezone: "Europe/Madrid" }
│   └── output: "2025-12-17T14:30:00"
├── llm (second LLM call)
└── output: "The current time in Madrid is 14:30"
```

## Targeting Spans

In your eval YAML, you target spans by their name:

```yaml
- name: datetime_test
  runnable: agent.py::agent
  params:
    prompt: "what time is it in madrid"
  
  # Target the final output
  output:
    contains!: ":"
  
  # Target overall timing
  elapsed:
    lt!: 5000
  
  # Target a specific tool span
  get_datetime:
    input:
      timezone:
        eq!: "Europe/Madrid"
    output:
      type!: "string"
```

## Available Targets

### output

The agent's final output content:

```yaml
output:
  type!: "string"
  contains!: "result"
  min_length!: 10
```

### elapsed

Total execution time in milliseconds:

```yaml
elapsed:
  lt!: 5000
  gte!: 100
```

### Tool Spans

Any tool called during execution, referenced by function name:

```yaml
get_datetime:
  input:
    timezone:
      eq!: "Europe/Madrid"
  output:
    type!: "string"
  elapsed:
    lt!: 1000
```

### llm

LLM call spans with usage metrics:

```yaml
llm:
  elapsed:
    lt!: 3000
  usage:
    input_tokens:
      lte!: 500
    output_tokens:
      lte!: 1000
```

## Span Properties

Each span has these properties you can validate:

| Property | Description |
|----------|-------------|
| `input` | Input parameters passed to the tool |
| `output` | Return value from the tool |
| `elapsed` | Execution time in milliseconds |
| `usage` | Token usage (for LLM calls) |

### Input Validation

Validate tool input parameters:

```yaml
get_datetime:
  input:
    timezone:
      eq!: "Europe/Madrid"
      starts_with!: "Europe/"

search_products:
  input:
    query:
      contains!: "laptop"
    limit:
      lte!: 100
```

### Output Validation

Validate tool return values:

```yaml
get_datetime:
  output:
    type!: "string"
    pattern!: "^\\d{4}-\\d{2}-\\d{2}"
    gt!: "2025-01-01"
    lte!: "2026-01-01"

search_products:
  output:
    type!: "array"
    min_length!: 1
```

### Timing Validation

Validate execution time per span:

```yaml
get_datetime:
  elapsed:
    lt!: 1000

llm:
  elapsed:
    lte!: 40000
```

### Usage Validation

Validate token usage on LLM spans:

```yaml
llm:
  usage:
    input_tokens:
      lte!: 500
    output_tokens:
      lte!: 1000
```

## Nested Field Access

Access nested properties in inputs and outputs:

```yaml
get_user:
  output:
    profile:
      name:
        eq!: "Alice"
      email:
        email!: true

search_products:
  input:
    options:
      limit:
        lte!: 100
      sort_by:
        eq!: "price"
```

## Usage Resolution

When your agent uses multiple models, usage metrics are resolved intelligently:

### Single Model

If only one model was used, metrics are returned directly:

```yaml
llm:
  usage:
    input_tokens:
      lte!: 500
```

### Multiple Models

If multiple models were used, metrics are summed across all models:

```yaml
llm:
  usage:
    input_tokens:
      lte!: 1000  # Sum of all models' input tokens
```

## Flow Validators and Traces

Flow validators (`seq!` and `parallel!`) operate on the trace structure:

### Sequence Validation

```yaml
seq!:
  - llm
  - get_datetime
  - llm
```

Checks that spans appear in this order in the trace.

### With Span Validation

```yaml
seq!:
  - llm:
      elapsed:
        lt!: 3000
  
  - get_datetime:
      input:
        timezone:
          eq!: "Europe/Madrid"
  
  - llm
```

### Parallel Validation

```yaml
parallel!:
  - get_datetime
  - get_weather
  - get_stock_price
```

Checks that these spans had overlapping execution times.

## Complete Example

```yaml
- name: comprehensive_trace_test
  runnable: agent.py::agent
  params:
    prompt: "what time is it in madrid"
  
  # Final output validation
  output:
    type!: "string"
    min_length!: 10
    contains!: ":"
    pattern!: "\\d{1,2}:\\d{2}"
    semantic!: "a time response mentioning Madrid"
  
  # Overall timing
  elapsed:
    lt!: 6000
  
  # Execution sequence with span validation
  seq!:
    - llm:
        elapsed:
          lte!: 40000
        usage:
          input_tokens:
            lte!: 1000
    
    - get_datetime:
        input:
          timezone:
            eq!: "Europe/Madrid"
            starts_with!: "Europe/"
            ends_with!: "rid"
        output:
          type!: "string"
          pattern!: "^\\d{4}-\\d{2}-\\d{2}"
          gt!: "2025-12-15T00:45:12"
        elapsed:
          lt!: 1000
    
    - llm
```

## Debugging Traces

If validation isn't working as expected:

1. **Run with debug logging**:
   ```bash
   python -m timbal.evals --log-level DEBUG eval_file.yaml
   ```

2. **Check span names**: Span names come from your tool function names

3. **Verify path exists**: Use `not_null!` to check intermediate paths:
   ```yaml
   get_datetime:
     input:
       not_null!: true
     output:
       not_null!: true
   ```

## Tips

<Tip>
Tool span names match your Python function names. If you rename a tool, update your eval targets.
</Tip>

<Note>
The `elapsed` values are in milliseconds throughout the eval system.
</Note>

<Warning>
Nested field access (e.g., `output.items.0`) assumes the structure exists. Validate parent fields first if needed.
</Warning>
